name: Tourism Project Pipeline

on:
  push:
    branches:
      - main  # Automatically triggers on push to the main branch

jobs:

  register-dataset:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Show repo tree (debug)
        run: |
          echo "PWD: $(pwd)"
          find . -maxdepth 3 -type f | sort || true

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f tourism_project/requirements.txt ]; then
            pip install -r tourism_project/requirements.txt
          elif [ -f week_3_mls/requirements.txt ]; then
            pip install -r week_3_mls/requirements.txt
          elif [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            echo "No requirements.txt found; installing minimal deps..."
            pip install pandas scikit-learn xgboost mlflow joblib huggingface_hub datasets requests
          fi

      - name: Upload Dataset to Hugging Face Hub
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: python tourism_project/model_building/data_register.py

  data-prep:
    needs: register-dataset
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f tourism_project/requirements.txt ]; then
            pip install -r tourism_project/requirements.txt
          elif [ -f week_3_mls/requirements.txt ]; then
            pip install -r week_3_mls/requirements.txt
          elif [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            echo "No requirements.txt found; installing minimal deps..."
            pip install pandas scikit-learn xgboost mlflow joblib huggingface_hub datasets requests
          fi

      - name: Run Data Preparation
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: python tourism_project/model_building/prep.py

  model-training:
    needs: data-prep
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f tourism_project/requirements.txt ]; then
            pip install -r tourism_project/requirements.txt
          elif [ -f week_3_mls/requirements.txt ]; then
            pip install -r week_3_mls/requirements.txt
          elif [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            echo "No requirements.txt found; installing minimal deps..."
            pip install pandas scikit-learn xgboost mlflow joblib huggingface_hub datasets requests
          fi

      - name: Start MLflow Server
        run: |
          nohup mlflow ui --host 0.0.0.0 --port 5000 &  # Run MLflow UI in the background
          sleep 5  # Wait for a moment to let the server starts
      - name: Model Building
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: python tourism_project/model_building/train.py

  deploy-hosting:
    runs-on: ubuntu-latest
    needs: [model-training, data-prep, register-dataset]
    steps:
      - uses: actions/checkout@v3

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f tourism_project/requirements.txt ]; then
            pip install -r tourism_project/requirements.txt
          elif [ -f week_3_mls/requirements.txt ]; then
            pip install -r week_3_mls/requirements.txt
          elif [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            echo "No requirements.txt found; installing minimal deps..."
            pip install pandas scikit-learn xgboost mlflow joblib huggingface_hub datasets requests
          fi

      - name: Push files to Frontend Hugging Face Space
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: python tourism_project/hosting/hosting.py
